{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b57236df-612b-43b9-bee0-a6d409651330",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dff86e-8a39-4617-b81f-7f8979c669bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi-layer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf65840-f264-4f2f-b24b-70e1087ffd37",
   "metadata": {},
   "source": [
    "**Triangle problem:**\n",
    "\n",
    "- Features: $x=(x_1,x_2)$\n",
    "- Target: $y\\in\\{+1,-1\\}$\n",
    "\n",
    "- Data: Triangle Behaviour.\n",
    "- Model: \n",
    "\n",
    "    - 3 logistic regression per a subproblem: $z_1(x)$, $z_2(x)$ and $z_3(x)$\n",
    "    - This gives us 3 new features.\n",
    "    - A point belong to class $+1$ if all the features have good results.\n",
    "    \n",
    "\n",
    "<center/> <img src=\"Images/Triangle_problem.png\" width=\"350\" height=\"280\" /> </center/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ad15f-5feb-43e7-b381-eda2f9bb36e9",
   "metadata": {},
   "source": [
    "**Multi-layer perceptron (MLP):**\n",
    "\n",
    "- Nodes: Compute variables $(x_1,\\cdots,z_3,a)$. Here each node is called the **neuron**.\n",
    "- Edges: Dependencies (Stablish hierarchy, it is necessary compute a varible with the previones one).\n",
    "- Process:\n",
    "    - Take a linear combination of inputs.\n",
    "    - Apply activation function $(\\sigma(x))$\n",
    "    \n",
    "<center><img src=\"Images\\MLP.png\" width=\"350\" height=\"280\" /> </center>  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3344e8-7c6c-4917-b340-94b74987c189",
   "metadata": {},
   "source": [
    "**Structure of Artificial neurons:**\n",
    "\n",
    "<center><img src=\"Images\\Artificial_Neuron.png\" width=\"350\" height=\"280\"> </center>\n",
    "\n",
    "- Architecture of an MLP:\n",
    "    - Number of layers\n",
    "    - Number of neurons in each layer\n",
    "    - Activation function\n",
    "- Hidden layer in MLP:\n",
    "    - Dense layer    \n",
    "    - Fully-connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2711dc4-e960-4634-85ae-a40f5b46bbb7",
   "metadata": {},
   "source": [
    "# Backpropagation Algorithm\n",
    "\n",
    "Compute derivates in the previous network could be difficult when we work with millions of neurons. For this reason, we need compute it efficiently. To do that, we going to reuse computations from previous steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acbd16d-bbbc-4d60-a976-ff64e32abe94",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Introduction to Deep Learning - HSE University - Coursera course.\n",
    "\n",
    "[2]  D. Smilkov, S. Carter - Tinker With a Deep playground - http://playground.tensorflow.org\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
